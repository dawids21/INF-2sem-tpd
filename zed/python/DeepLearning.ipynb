{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "hDA96d-SMw_A"
      },
      "source": [
        "# Uczenie głębokie cz. I\n",
        "\n",
        "Ten notatnik ma na celu przedstawienie jednego ze sposobów tworzenia głębokich sieci neuronowych w Pythonie. W trakcie zadania najpierw stworzymy prostą sieć konwolucyjną, a następnie zbadamy jej proces uczenia się. Na tych zajęciach wykorzystamy biblioteki [Keras](https://keras.io/) i [Tensorflow](https://www.tensorflow.org/).\n",
        "\n",
        "Po wykonaniu tego zadania powinieneś:\n",
        "+ wiedzieć z jakich części składają się sieci konwolucyjne,\n",
        "+ potrafić uruchomić sieć neuronową na własnych danych,\n",
        "+ wiedzieć jak wczytać i wykorzystać gotowy model,\n",
        "+ zwizualizować i śledzić na żywo proces uczenia się sieci."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDWRA71zMw_C"
      },
      "source": [
        "## Prosta sieć konwolucyjna\n",
        "\n",
        "Najpierw załadujemy odpowiednie biblioteki i wczytamy mały zbiór obrazów do uczenia się rozpoznawania liczb.\n",
        "\n",
        "**Zad. 1:Przejrzyj komentarze przy operacjach `import`, aby zapoznać się z nazewnictwem w bibliotece Keras.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T7WWJH2RMw_C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(23)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(23)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Typ sieci\n",
        "from tensorflow.keras.models import Sequential # tworzymy typową sieć jednokierunkową (bez rekurencji)\n",
        "\n",
        "# Typy warstw\n",
        "from tensorflow.keras.layers import Dense # warstwa z w pełni połączona (wszystkie neurony z poprzedniej warstwy do każdego w kolejnej)\n",
        "from tensorflow.keras.layers import Dropout # mechanizm losowego wyłączania neuronów (pozwala uniknąć przeuczenia)\n",
        "from tensorflow.keras.layers import Activation # aktywacja, czyli funkcja przyjmująca jedną liczbę (np. sigmoid, softmax)\n",
        "from tensorflow.keras.layers import Flatten # spłaszczenie wejścia (np. zamiana tensora o wymiarach 64x32x32 na wektor o długości 65536)\n",
        "from tensorflow.keras.layers import Conv2D # warstwa konwolucyjna, tworzy filtry o zadanym rozmiarze w zadanych odstępach\n",
        "from tensorflow.keras.layers import MaxPooling2D # warstwa zmniejszająca obraz poprzez operacje max na zadanym rozmiarze pikseli\n",
        "\n",
        "# Optymalizator i funkcja straty\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "# \"Przydasie\"\n",
        "from tensorflow.keras import utils as k_utils\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8_H6KuwMw_D"
      },
      "source": [
        "Czas na zbiór danych. Skorzystamy ze standardowego zbioru treningowego do omawiania sieci konwolucyjnych, czyli [MNIST](http://yann.lecun.com/exdb/mnist/). Zbiór składa się z małych obrazków, więc będziemy w stanie nauczyć sieć na zwykłym komputerze, a sieci konwolucyjne są tu jak najbardziej potrzebne do uzyskania sensownych wyników.\n",
        "\n",
        "Biblioteka Keras ma funkcję pobierającą ten zbiór z sieci, z czego skrzętnie skorzystamy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qbQaVsA9Mw_D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN9r1pJZMw_D"
      },
      "source": [
        "**Zad. 2: Sprawdź jakie wymiary mają załadowane obrazki. Przypisz te wartości do zmiennych img_rows, img_cols. Sprawdź również liczbę klas i przypisz tę wartość to zmiennej `num_classes`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9-0QrWVpMw_D"
      },
      "outputs": [],
      "source": [
        "# sprawdź wymiary zbioru danych\n",
        "\n",
        "img_rows = X_train[0].shape[0]\n",
        "img_cols = X_train[0].shape[1]\n",
        "num_classes = len(set(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CY1x2XLMw_E"
      },
      "source": [
        "**Zad. 3: Wyświetl pierwszy rysunek ze zbior.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mo2JZrV4Mw_E"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2100a9d3d30>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X_train[0], cmap='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNkumI6tMw_E"
      },
      "source": [
        "## Wstępne przetwarzanie danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak0aoe8LMw_E"
      },
      "source": [
        "Ponieważ obrazy mogą mieć różną liczbę kolorów (kanałów), musimy powiedzieć Kerasowi jaki format danych będzie przetwarzać. Obrazy mogą mieć jeden kanał (skala szarości), trzy kanały (RGB), a czasami więcej niż trzy kanały (np. zdjęcia satelitarne). Dane w zbiorze MNIST są zakodowane w skali szarości, a zatem mają jeden kanał.\n",
        "\n",
        "**Zad. 4: Zmień wymiarowość danych wejściowych zgodnie z poniższym wzorem.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTiUENKVMw_E"
      },
      "outputs": [],
      "source": [
        "# X_train = X_train.reshape(X_train.shape[0], l_wierszy, l_kolumn, l_kanalow)\n",
        "# X_test = X_test.reshape(X_test.shape[0], l_wierszy, l_kolumn, l_kanalow)\n",
        "# input_shape = (l_wierszy, l_kolumn, l_kanalow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7j8vzpnMw_E"
      },
      "source": [
        "Oprócz określenia wymiaru danych wejściowych musimy upewnić się, że są one typu `float32`. Ponadto warto ustandaryzować dane wejściowe lub sprowadzić je do zakresu [0-1]. My uczynimy to drugie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NlfWtwrMw_E",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# X_train = X_train.astype('float32')\n",
        "# X_test = X_test.astype('float32')\n",
        "# X_train /= 255\n",
        "# X_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tZp2UqvMw_E"
      },
      "source": [
        "Ostatnia rzecz, którą musimy zrobić to zakodować klasy (`y`) w sposób binarny. Czyli zamiast klas `1, 2, ... 10` itd., chcemy uzyskać kodowanie w postaci `[1 0 0 0 0 0 0 0 0 0], [0 1 0 0 0 0 0 0 0 0] ... [0 0 0 0 0 0 0 0 0 1]`. W Kerasie posłuży nam do tego funkcja `to_categorical()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5p_dK9NMw_E"
      },
      "outputs": [],
      "source": [
        "# y_train = k_utils.to_categorical(y_train, num_classes)\n",
        "# y_test = k_utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddK16DJDMw_F"
      },
      "source": [
        "## Tworzenie sieci\n",
        "\n",
        "W Kerasie **architekturę sieci** definiuje się poprzez podanie typu sieci i kolejnych warstw. Dla każdej warstwy określa się typ neuronów, ich liczbę i (jeśli to konieczne) ich parametry.\n",
        "\n",
        "Poniżej zdefiujemy prostą sieć konwolucyjną. Będzie się ona składała tylko z dwóch warstw konwolucyjnych, bo zdjęcia na których operujemy są bardzo małe. Większe zdjęcia wymagałyby więcej warstw. Uwaga! W uporszczeniu: im większa sieć tym większe wymagania pamięciowe i czasowe!\n",
        "\n",
        "Nasza architektura to (porównaj z poniższym kodem):\n",
        "- **warstwa konwolucyjna** tworząca **32 filtry** o rozmiarze **3x3**. Każdy filtr stanowi wejście dla funkcji atywacyjnej typu **ReLU**. Zauważ, że w pierwszej warstwie sieci musimy podać wymiary (warstwę wejściową). W kolejnych warstwach nie jest to konieczne, bo warstwy wiedzą jak mają się łączyć.\n",
        "- **warstwa konwolucyjna** tworząca **64 filtry** o rozmiarze **3x3** z **ReLU**.\n",
        "- **warstwa pooling** zmiejszająca obraz o połowę\n",
        "- **warstwa dropout** losowo wyłączają 1/4 neuronów przy każdym przejściu\n",
        "- **warstwę spłaszczającą** wielowymiarowe konwolucje w wektor\n",
        "- **w pełni połączona warstwa** 128 neuronów\n",
        "- **kolejny dropout**\n",
        "- **warstwa wyjściowa** posiadającą tyle neuronów ile mamy klas\n",
        "\n",
        "**Zad. 5: W ostatniej warstwie nie jest podana funkcja aktywacji. Wróć do slajdów i sprawdź jaka funkcja aktywacji nada się do klasyfikacji.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0tFyxvVMw_F"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(num_classes, activation='?'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar-m1GvBMw_F"
      },
      "source": [
        "Po stworzeniu sieci w Kerasie trzeba ją skompilować. W tym kroku Keras dostosowuje kod pod wykonanie na wybranym backendzie. W naszym przypadku będzie to Tensorflow, ale równie dobrze mogłyby to być platformy Theano lub CNTK.\n",
        "\n",
        "Podczas kompilacji podajemy **funkcję straty**, **optymalizator**. Ponadto można podać szereg miar do śledzenia (typowo przy klasyfikacji accuracy).\n",
        "\n",
        "**Zad. 6: Wróć do slajdów i sprawdź jaka funkcja straty nada się do klasyfikacji wieloklasowej. Jako optymalizator wybierz Adadelta, dzięki temu nie będziesz musiał podawać learning rate. Protip: użyj Tab.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTnuKmpoMw_F"
      },
      "outputs": [],
      "source": [
        "# model.compile(loss=losses.?,\n",
        "#               optimizer=optimizers.?,\n",
        "#               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxubVMMUMw_F"
      },
      "source": [
        "## Uczenie sieci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYIDcq6GMw_F"
      },
      "source": [
        "Mamy sieć. Teraz nic tylko odpalić uczenie. Robiąc to musimy podać **batch_size** (czyli ile przykładów przepuszczamy przez sieć między aktualizacją wag) i liczbę **epok** (czyli ile razy chcemy przepuścić przez sieć cały zbiór danych). Zbiór walidacyjny będzie nam mówił na ile dobrze sieć działa na danych, których wcześniej nie widzieliśmy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoTAQUibMw_F"
      },
      "outputs": [],
      "source": [
        "# model.fit(X_train, y_train,\n",
        "#           batch_size=128,\n",
        "#           epochs=12,\n",
        "#           verbose=1,\n",
        "#           validation_data=(X_test, y_test))\n",
        "\n",
        "# Jak kod ruszy, oszacuj ile zajmie uczenie sieci (ETA jednej epoki x liczba epok).\n",
        "# Jeśli wychodzi Ci więcej niż 3 minuty zatrzymaj uczenie i czytaj dalej..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf6kNUDqMw_F"
      },
      "source": [
        "Spójrzmy na ETA. Aha, ale to tylko 1 epoka z 12... Hmmm.... Trochę będzie trzeba poczekać. Zatrzymaj powyższy blok kodu. Zaraz coś z tym zrobimy..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkRzeWYkMw_F"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Uczenie sieci to bardzo czasochłonny proces. Na szczeście, ze względu na swoją modularność, sieci bardzo łatwo się zrównolegla. Stąd gotowość większości bibliotek do współpracy z kartami graficznymi (jednakże obecnie są to praktycznie tylko karty NVidii).\n",
        "\n",
        "Ponieważ prawdopodobnie nie masz komputera z super-ekstra kartą graficzną do obliczeń równoległych, skorzystamy z karty graficznej w chmurze. AWS, Google Cloud, Microsoft Azure chętnie udostępnią swoje moce obliczeniowe za drobną opłatą. Maszyny wirtualne z GPU są stosunkowo drogie w porównaniu do innych maszyn, ale przy naliczaniu godzinowym (a niekiedy sekundowym) jest to bardzo interesująca opcja. Jeśli masz dostęp do jednej z tych platform, albo lepiej dostęp i niewykorzystany kredyt, warto z tego skorzystać.\n",
        "\n",
        "Aby zaoszczędzić sobie czasu nie będziemy stawiać pełnoprawnych wirtualek na żadnej z wymienionych platform. Zamiast tego proponuję szybko odpalić Google Colab (https://colab.research.google.com/) i tam wgrać ten notebook.\n",
        "1. Wejdź na https://colab.research.google.com/.\n",
        "2. Kliknij **Plik -> Prześlij notatnik**\n",
        "3. Z menu **Środowisko wykonawcze** wybierz **Zmień typ środowiska wykonawczego** i wybierz maszynę z **GPU**\n",
        "4. Zacznij odpalać kod\n",
        "\n",
        "**Zad 7. Wykonaj powyższe kroki i naucz sieć z tego notebooka na GPU. Po zakończeniu obliczeń zapisz model do pliku za pomocą poniższego kodu. Następnie ściągnij utworzony plik modelu i zamknij zdalnego Jupytera.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsBIDnTZMw_F"
      },
      "outputs": [],
      "source": [
        "# model.save(\"gpu_cnn_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PXVvM16Mw_F"
      },
      "source": [
        "## Wczytywanie modelu i predykcje\n",
        "\n",
        "Uczenie się trwa długo, ale jak już mamy nauczoną sieć to wcale nie zajmuje ona aż tyle miejsca na dysku i działa bardzo szybko. Sprawdźmy czy tak rzeczywiście jest.\n",
        "\n",
        "**Zad. 8: Wczytaj model nauczony na GPU na swoim lokalnym komputerze i dokonaj predykcji zgodnie z poniższym szablonem.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKB7aDngMw_F"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# gpu_model = load_model(\"gpu_cnn_model.keras\") # w razie co do projektu jest też załączony wcześniej nauczony \"cnn_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4f2In19Mw_G"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# score = gpu_model.evaluate(X_test, y_test, verbose=0)\n",
        "# print('{0} przykładów'.format(X_test.shape[0]))\n",
        "# print('loss={0:.4f}, accuracy={1:.4f}'.format(score[0], score[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrbQDosCMw_G"
      },
      "source": [
        "U mnie na laptopie wyszło ok. 9 sekund. Dzieląc to przez liczbę przykładów wychodzi 10000/9 = 1111 obrazów na sekundę, czyli nie tak źle. Zwłaszcza, że mój komputer ma ponad 5 lat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-pGWIeKMw_G"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzGk3JTSMw_G"
      },
      "source": [
        "Tensorflow udostępnia świetne narzędzie do wizualizacji procesu uczenia sieci o nazwie **Tensorboard**. Aby je uruchomić odpal Anaconda Prompt i wpisz następujące polecenie:\n",
        "\n",
        "```\n",
        "tensorboard --logdir=\"pelna_sciezka_do_tego_notebooka/logs\"\n",
        "```\n",
        "Jeżeli korzystasz z Colaba odkomentuj odpowiednie komórki (z komentarzem tylko w colabie)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYl1VfKyOcrv"
      },
      "outputs": [],
      "source": [
        "#tylko w colabie\n",
        "#%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYFcRJ4_OO04"
      },
      "source": [
        "\n",
        "**Zad. 9: Odpal Tensorboarda a następnie uruchom (lokalnie) poniższy kod. W trakcie gdy sieć się uczy wejdź na stronę Tensorboard i sledź zmiany.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfhSc6NdMw_G"
      },
      "outputs": [],
      "source": [
        "# epochs = 12\n",
        "# batch_size = 128\n",
        "# dataset_size = 1000\n",
        "\n",
        "# # Protip: w nazwie modelu zawrzyj wartości parametrów, wtedy będzie można łatwo porównywać różne architektury/parametry\n",
        "# model_name = \"cpu_cnn_model\" + \\\n",
        "#     \"_e=\" + str(epochs) + \"_b=\" + str(batch_size) + \\\n",
        "#     \"_n=\" + str(dataset_size) + \"_t=\" + time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
        "\n",
        "# tb_callback = TensorBoard(log_dir=\"./logs/\" + model_name, histogram_freq=-1)\n",
        "\n",
        "# model.fit(X_train[:dataset_size,:,:,:], y_train[:dataset_size,:],\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,\n",
        "#           validation_data=(X_test[:dataset_size,:,:,:], y_test[:dataset_size,:]),\n",
        "#           callbacks=[tb_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jWOQie8OpXU"
      },
      "outputs": [],
      "source": [
        "#tylko w colabie\n",
        "#%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42PgIqZBMw_G"
      },
      "source": [
        "**Zad. 10: Zmień batch size na 64, zbuduj i skompiluj ponownie sieć (kod z zad. 5 i 6) i odpal uczenie jeszcze raz. Porównaj krzywe uczenia w Tensorboard.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onc52HxUMw_G"
      },
      "source": [
        "Poznałeś podstawy tego co jest potrzebne aby nauczyć własną głęboką sieć neuronową od zera. O tym jakie inne architektury zaproponowano do różnych zadań i jak przyspieszyć proces uczenia sieci dla wielu standardowych problemów dowiesz się w kolejnym notebooku."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
