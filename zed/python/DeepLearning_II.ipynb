{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "RZgb9DUdSKWR"
      },
      "source": [
        "# Uczenie głębokie cz. II\n",
        "\n",
        "Ten notatnik ma na celu przedstawienie sposobów wykorzystania uczenia głębokiego w różnych zastosowaniach. W trakcie zadania najpierw dostosujemy istniejącą sieć konwolucyjną do nowych danych, zobaczymy jak stosować sieci do rekomendowania produktów oraz jak nauczyć klasyfikator tekstowy. Na tych zajęciach wykorzystamy bibliotekę [pytorch-lightning](https://lightning.ai/docs/pytorch/stable/), która jest wrapperem na [PyTorch](https://pytorch.org/) oraz, tak jak ostatnio, [Keras](https://keras.io/). Poniższe skrypty są w istocie kompilacją różnych materiałów szkoleniowych do pytorch (w tym też torchvision i pytorch-geometric), pytorch-lightning i Kerasa.\n",
        "\n",
        "Po wykonaniu tego zadania powinieneś:\n",
        "+ wiedzieć dostosować istniejącą architekturę (wraz z wagami) do własnego problemu,\n",
        "+ wiedzieć jak zamrażać warstwy sieci,\n",
        "+ umieć zastosować sieć neuronową do danych tekstowych,\n",
        "+ potrafić stworzyć sieć grafową."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTNaOx_iSKWY"
      },
      "source": [
        "## Przygotowanie środowiska\n",
        "\n",
        "Ćwiczenie wykonamy na platformie [Google Colab](https://colab.research.google.com/), aby nie musieć instalować bibliotek i zbiorów danych lokalnie. W Colabie wybieramy runtime z GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEAJgapDSKWa"
      },
      "source": [
        "## Rozpoznawanie obrazów\n",
        "\n",
        "Spróbujemy nauczyć sieć rozpoznającą typy terenu na zdjęciach satelitarnych. W tym celu wykorzystamy sieć nauczoną na zbiorze danych ImageNet, która umie klasyfikować pojedyncze obiekty na zdjęciach (psy, koty, czołgi, itp.). W naszym problemie będziemy musieli rozpoznać kilka rodzajów terenu na każdym zdjęciu (multi-label classification) i nie będą one przypominały obiektów ze zbioru ImageNet.\n",
        "\n",
        "W zadaniu wykorzystamy pytorch-lightning, pytorch i torchvision. Pokażemy też, jak używać tensorboard z lightningiem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "BHBdwJEuxhIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "o50PS_j9EjZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpx8seJCSKWa"
      },
      "source": [
        "### Dane\n",
        "\n",
        "Dane pochodzą z zakończonego konkursu na Kaggle o nazwie [Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space). Najpierw pobierzmy dane:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('data/planet', exist_ok=True)\n",
        "!wget \"https://drive.google.com/u/3/uc?id=1doTIfs4q9zxINS4WKdypd15p6y7VN02Y&export=download&confirm=yes\" -O data/planet/train_v2.csv\n",
        "!wget \"https://drive.usercontent.google.com/download?id=1DIJhHbmKX0wZk4I1e8mmhA4Pss-xPPBK&export=download&confirm=yes\" -O data/planet/train-jpg.zip\n",
        "!unzip data/planet/train-jpg.zip -d data/planet/"
      ],
      "metadata": {
        "id": "Xbc056LkTald"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jeżeli pobieranie się udało zobaczmy jak wyglądają przykładowe zdjęcia satelitarne."
      ],
      "metadata": {
        "id": "M6vg9L1Ftcw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plots_from_files(list_paths, titles=None, maintitle=None, figsize=(10, 5)):\n",
        "  num_images = len(list_paths)\n",
        "  fig, axs = plt.subplots(1, num_images, figsize=figsize)\n",
        "  if maintitle:\n",
        "      fig.suptitle(maintitle, fontsize=16)\n",
        "  if num_images == 1:\n",
        "      axs = [axs]  # Ensure axs is iterable when there's a single image\n",
        "  for ax, img_path, title in zip(axs, list_paths, titles):\n",
        "      img = mpimg.imread(img_path)\n",
        "      ax.imshow(img)\n",
        "      ax.axis('off')\n",
        "      if title:\n",
        "          ax.set_title(title, fontsize=10)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "list_paths = [f\"data/planet/train-jpg/train_0.jpg\", f\"data/planet/train-jpg/train_1.jpg\"]\n",
        "titles=[\"haze primary\", \"agriculture clear primary water\"]\n",
        "\n",
        "plots_from_files(list_paths, titles=titles, maintitle=\"Multi-label classification\")\n"
      ],
      "metadata": {
        "id": "i6afBmbkif99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6su8Q5lSKWb"
      },
      "source": [
        "Zdjęcie po lewej ma etykiety (klasy) *haze* i *primary*, a zdjęcie po prawej ma etykiety *agriculture*, *clear*, *primary* i *water*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3fGZOwuSKWb"
      },
      "source": [
        "### Ładowanie danych do sieci\n",
        "\n",
        "W pierwszej kolejności ustalimy sposób ładowania danych do sieci i transformacje, któych chcemy użyć.\n",
        "\n",
        "Najpierw zapoznajmy się z plikiem zawierającym etykiety."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "label_csv = f'data/planet/train_v2.csv' # plik csv z połączeniem nazwa_obrazu-etykiety\n",
        "label_csv = pd.read_csv(label_csv)\n",
        "label_csv.head()"
      ],
      "metadata": {
        "id": "SqbBSZrktvRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby móc pracować z naszym datasetem w pytorchu, musimy zaimplementować specjalną strukturę (Dataset), która obsłuży czytanie plików i łączenie ich z etykietami.\n",
        "\n",
        "Tutaj też będziemy podawać nasze transformacje, które chcemy zaaplikować do obrazów.\n",
        "\n",
        "**Zadanie 1.1: Zaencoduj etykiety, tak aby zamiast aktualnej formy (tj. zwykłego stringa, np. \"haze primary\") otrzymać wektor z 1, jeśli dany obraz posiada daną etykietę i 0, jeśli nie posiada (zakładając, że w zbiorze są trzy etykiety, np. \"haze\", \"primary\", \"clear\" i encodujemy jest w takiej kolejności, dla przykładu \"haze primary\" powinniśmy otrzymać [1, 1, 0])**\n",
        "\n",
        "Odpowiedni import jest już zrobiony - zobacz, czego możesz użyć."
      ],
      "metadata": {
        "id": "SjkYlaRmGukM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "class PlanetDataset(Dataset):\n",
        "  def __init__(self, csv_file: str, root_dir: str, transform=None):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "\n",
        "    data = self._filter_data(data)\n",
        "    self.data_files = data['image_name'].to_list()\n",
        "\n",
        "    #encodowanie etykiet - użyj data['tags'] i zesplituj, żeby uzyskać listy\n",
        "    labels = ...\n",
        "\n",
        "    self.mlb = ...\n",
        "    labels = ...\n",
        "    self.n_classes = ...\n",
        "    self.labels = torch.Tensor(labels)\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def _filter_data(self, data: pd.DataFrame):\n",
        "    # funkcja do odrzucenia wierszy z csvki, do któych nie ma obrazów w naszych danych\n",
        "    data_files = [i.split('.')[0] for i in os.listdir(self.root_dir)]\n",
        "    correct_files = data.loc[:, 'image_name'].isin(data_files)\n",
        "    return data.loc[correct_files, :]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # zwraca obraz i jego etykietę, aplikuje transformacje do obrazu, jęsli zostały podane\n",
        "    label = self.labels[idx, :]\n",
        "    img_name = os.path.join(self.root_dir, f\"{self.data_files[idx]}.jpg\")\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "dPd9-nKP0po7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jak wspominałam na zajęciach, pytorch-lightning jest pewną formą uprządkowania kodu pytorcha. Szcególnie ważne są tutaj dwie struktury: `LightningDataModule` i `LightningModule`. Najpierw omówmy ten pierwszy. `LightningDataModule` zajmuje się obsługą danych, podziałem danych na zbiory treningowy i testowy, a także zadeklarowaniem DataLoaderów, które podzielą nasz Dataset na batche.\n",
        "\n",
        "Poniżej implementujemy `PlanetDataModule`, czyli `LightningDataModule` dedykowany dla naszego zbioru. To tutaj m.in. określamy transformacje, które zostaną zaaplikowane do naszych obrazów.\n",
        "\n",
        "Do zbioru treningowego chcemy jednak użyć nieco innych transformacji niż do zbiorów walidacyjnego i testowego.\n",
        "\n",
        "**Zadanie 1.2: Używając torchvision (zaimportowany moduł v2) dodaj następujące transformacje do `self.train_transform`:**\n",
        "\n",
        "* random crop\n",
        "* odbicie (horizontal, z prawdopodobieństwem 0.5)\n",
        "* rotacja (15 stopni)\n"
      ],
      "metadata": {
        "id": "IFNX29c-vrfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as L\n",
        "from pytorch_lightning import seed_everything\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "class PlanetDataModule(L.LightningDataModule):\n",
        "  def __init__(self, batch_size=32, train_size=0.8, val_size=0.1, test_size=0.1, seed=42, num_workers=3):\n",
        "    super().__init__()\n",
        "    seed_everything(seed, workers=True)\n",
        "    self.batch_size = batch_size\n",
        "    self.train_size = train_size\n",
        "    self.val_size = val_size\n",
        "    self.test_size = test_size\n",
        "    self.num_workers = num_workers\n",
        "    self.generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "    self.train_transform = v2.Compose([\n",
        "        v2.ToImage(),\n",
        "        v2.Resize((64, 64)),\n",
        "        ...,        #tutaj dodaj potrzebne transformacje\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    self.val_test_transform = v2.Compose([\n",
        "        v2.ToImage(),\n",
        "        v2.Resize((64, 64)),\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    self.setup()\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    dataset = PlanetDataset('data/planet/train_v2.csv', 'data/planet/train-jpg')\n",
        "    train_size = int(self.train_size * len(dataset))\n",
        "    val_size = int(self.val_size * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
        "        dataset, [train_size, val_size, test_size], generator=self.generator)\n",
        "\n",
        "    self.train_dataset.dataset.transform = self.train_transform\n",
        "    self.val_dataset.dataset.transform = self.val_test_transform\n",
        "    self.test_dataset.dataset.transform = self.val_test_transform\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n"
      ],
      "metadata": {
        "id": "AC1vYvbzvi4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przechodzimy do implementacji wcześniej wspominanego `LightningModule`, w którym zawrzemy cały kod obsługujący sam model.\n",
        "\n",
        "Używamy pre-trenowanego Resneta18, dostępnego w ramach bilioteki torchvision. Następnie mrozimy wszystkie parametry modelu, oprócz warstw końcowych.\n",
        "\n",
        "Zamieniamy warstwę fully-connected oryginalnego resneta, aby odpowiadała naszemu zadaniu klasyfikacyjnemu. Podczas uczenia, tylko wagi `model.fc` będą aktualizowane.\n",
        "\n",
        "Ponadto wybieramy funkcję straty i metryki, które chcemy obliczać.\n",
        "Jako funkcję straty stosujemy Binary Cross Entropy, a z metryk obliczamy F2-score.\n",
        "\n",
        "Następnie implemetujemy poszczególne kroki uczenia - treningowy, walidacyjny i testowy.\n",
        "\n",
        "**Zadanie 1.3: Na podstawie funkcji `training_step` zaimplementuj `validation_step`. Zaloguj loss i F2-score otrzymany podczas walidacji (logując je odpowiednio pod 'val_loss' i 'val_f2')**"
      ],
      "metadata": {
        "id": "Mx7D7ifV9xhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "class PlanetModel(L.LightningModule):\n",
        "  def __init__(self, num_classes):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    model = resnet18(pretrained=True)\n",
        "\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    model.fc = torch.nn.Sequential(\n",
        "          torch.nn.Linear(model.fc.in_features, 512),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(512, num_classes),\n",
        "          torch.nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.model = model\n",
        "    self.criterion = torch.nn.BCELoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "  def _compute_f2(self, y_hat, y):\n",
        "    y_hat = (y_hat > 0.5).int().cpu().numpy()\n",
        "    y = y.int().cpu().numpy()\n",
        "    f2 = fbeta_score(y, y_hat, beta=2, average='samples')\n",
        "    return f2\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self.forward(x)\n",
        "    loss = self.criterion(y_hat, y)\n",
        "    f2 = self._compute_f2(y_hat, y)\n",
        "    self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "    self.log('train_f2', f2, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    ...\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self.forward(x)\n",
        "    loss = self.criterion(y_hat, y)\n",
        "    f2 = self._compute_f2(y_hat, y)\n",
        "    self.log('test_loss', loss, logger=True)\n",
        "    self.log('test_f2', f2, logger=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adadelta(self.parameters())\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "YwL0l15-w0rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mając już zaimplementowane wszytskie elementy, musimu połaczyć je w całość. Do tego użyjemy struktury `Trainer` z pytorch-lightning.\n",
        "\n",
        "Dodatkowo, użyjemy dwóch callbacków - do zapisu najlepszego modelu i do early stoppingu (wcześniejszego zatrzymywania się uczenia, gdy nie uzyskamy poprawy funkcji straty na zbiorze walidacyjnym przez ileś epok)."
      ],
      "metadata": {
        "id": "9ewH_CnMQAL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "data = PlanetDataModule(batch_size=256, num_workers=2)\n",
        "\n",
        "num_classes = data.train_dataset.dataset.n_classes\n",
        "\n",
        "model = PlanetModel(num_classes=num_classes)\n",
        "\n",
        "os.makedirs('data/planet/models', exist_ok=True)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    dirpath='data/planet/models',\n",
        "    filename=\"resnet18-{epoch:02d}-{val_loss:.2f}\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(max_epochs=20, callbacks=[checkpoint_callback, early_stopping_callback])\n",
        "trainer.fit(model, datamodule=data)"
      ],
      "metadata": {
        "id": "H7tCVCo1KHY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wytrenowany model możemy załadować z pliku i odpalić go na zbiorze testowym."
      ],
      "metadata": {
        "id": "PjSWHhQoQksJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'data/planet/models/resnet18-epoch=10-val_loss=0.14.ckpt'\n",
        "\n",
        "model = PlanetModel.load_from_checkpoint(model_path)\n",
        "trainer.test(model, datamodule=data)"
      ],
      "metadata": {
        "id": "UlWYrTKaE04B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wszystkie dotychczas zalogowane wyniki możemy zobaczyć w tensorboard."
      ],
      "metadata": {
        "id": "ibfwzUuCQuXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir lightning_logs/"
      ],
      "metadata": {
        "id": "gYOcedavEYpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EqgzOqUSKWd"
      },
      "source": [
        "### Keras\n",
        "\n",
        "Podobną metodologię, obejmującą generowanie sztucznych danych wraz z wykorzystaniem istniejącej architektury i wag, można oczywiście zaimplementować również w Kerasie. Krótki tutorial jak to zrobić znajdziesz na stronie: https://keras.io/guides/transfer_learning/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWsR57DCSKWd"
      },
      "source": [
        "## Sieci grafowe\n",
        "\n",
        "Grafowe sieci neuronowe stanowią dynamicznie rozwijającą się dziedzinę w obszarze uczenia maszynowego, oferując narzędzia do analizy danych o strukturze grafowej. W odróżnieniu od tradycyjnych sieci neuronowych, które operują na danych w formie wektorów czy macierzy, GNN pozwalają efektywnie przetwarzać i wyciągać informacje z danych, w których relacje pomiędzy elementami są równie istotne co same elementy. Przykłady takich danych obejmują sieci społeczne, grafy molekularne, sieci komunikacyjne czy systemy rekomendacji.\n",
        "\n",
        "My skupimy się na grafach molekularnych, a konkretniej na zbiorze [Proteins](https://chrsmrrs.github.io/datasets/).\n",
        "\n",
        "Zbiór Proteins jest dostępny bezpośrednio w [pytorch-geometric](https://pytorch-geometric.readthedocs.io/en/2.6.1/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "dgf0BEsUNy-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podobnie jak w przypadku poprzedniej sieci, także tutaj użyjemy pytorch-lightning.\n",
        "\n",
        "W tym przypadku nie musimy implementować osobnej struktury Dataset ze względu na to, że używamy gotowego zbioru danych dostępnego i w pełni wspieranego przez pytorch-geometric.\n",
        "\n",
        "Z tego względu, możemy przejść bezpośrednio do `LightningDataModule`.\n",
        "\n",
        "Tak jak poprzednio dzielimy dane na zbiór treningowy, walidacyjny i testowy.\n",
        "\n",
        "Podstawową różnicą między modułem, któego używaliśmy do obsługi danych obrazkowych jest typ używanego DataLoadera.\n",
        "\n",
        "Wcześniej używaliśmy torchowego DataLoadera, teraz wykorzystujemy ten z pytorch-geometric."
      ],
      "metadata": {
        "id": "gkyvp_aQRANp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atoRq4AVSKWd"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "import pytorch_lightning as L\n",
        "from pytorch_lightning import seed_everything\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "class ProteinDataModule(L.LightningDataModule):\n",
        "  def __init__(self, batch_size=32, train_size=0.8, val_size=0.1, test_size=0.1, seed=42, num_workers=3):\n",
        "    super().__init__()\n",
        "    seed_everything(seed, workers=True)\n",
        "    self.batch_size = batch_size\n",
        "    self.train_size = train_size\n",
        "    self.val_size = val_size\n",
        "    self.test_size = test_size\n",
        "    self.num_workers = num_workers\n",
        "    self.generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    os.makedirs('data/TUDataset', exist_ok=True)\n",
        "    dataset = TUDataset(root='data/TUDataset', name='PROTEINS', cleaned=True)\n",
        "    train_size = int(self.train_size * len(dataset))\n",
        "    val_size = int(self.val_size * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
        "        dataset, [train_size, val_size, test_size], generator=self.generator)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przechodzimy do modelu - tutaj tworzymy go sami z operatorów dostępnych w torch-geometric.\n",
        "\n",
        "Nasza sieć jest nieskomplikowanym GCNem z kilkoma warstwami konwolucji i zwykłą warstwą liniową z sigmoidem na końcu sieci. Używamy sigmoidu ze względu na to, że rozwiązujemy problem klasyfikacji binarnej. W przypadku wielu klas, należy użyć Softmaxa.\n",
        "\n",
        "**Zadanie 2.1: Uzupełnij punkt 3 (3. Apply a final classifier) zgodnie z powyższym opisem. Użyj warstwy liniowej (self.linear) oraz Sigmoidu na końcu sieci.**"
      ],
      "metadata": {
        "id": "D5kWxb2jSg3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_channels):\n",
        "      super(GCN, self).__init__()\n",
        "      torch.manual_seed(12345)\n",
        "      self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "      self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "      self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "      self.linear = torch.nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "      # 1. Obtain node embeddings\n",
        "      x = self.conv1(x, edge_index)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=0.2, training=self.training)\n",
        "      x = self.conv2(x, edge_index)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=0.2, training=self.training)\n",
        "      x = self.conv3(x, edge_index)\n",
        "\n",
        "      # 2. Readout layer\n",
        "      x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "      # 3. Apply a final classifier\n",
        "      x = ...\n",
        "      x = ...\n",
        "      return x"
      ],
      "metadata": {
        "id": "dAJTKdqKOJU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podobnie jak poprzednio implementujemy moduł do obsługi modelu (`LightningModule`). Tym razem jako modelu używamy GCN, jako funkcji straty - Bianry Cross Entropy, a z metryk obliczamy accuracy.\n",
        "\n",
        "**Zadanie 2.2: Uzupełnij funkcję `_compute_acc`, aby obliczyć accuracy. Inspiracją może być tutaj funkcja `_compute_f2` z poprzedniego zadania.**"
      ],
      "metadata": {
        "id": "DLWQpzFZTfXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProteinModel(L.LightningModule):\n",
        "    def __init__(self, num_node_features, num_hidden, lr=1e-2):\n",
        "      super().__init__()\n",
        "      self.save_hyperparameters()\n",
        "\n",
        "      self.lr = lr\n",
        "\n",
        "      self.model = GCN(num_node_features, num_hidden)\n",
        "\n",
        "      self.criterion = torch.nn.BCELoss()\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "      return self.model(x, edge_index, batch)\n",
        "\n",
        "    def _compute_acc(self, y_hat, y):\n",
        "      ...\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "      y_hat = self.forward(batch.x, batch.edge_index, batch.batch).float()\n",
        "      y = batch.y.unsqueeze(-1).float()\n",
        "      loss = self.criterion(y_hat, y)\n",
        "      acc = self._compute_acc(y_hat, y)\n",
        "      self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      y_hat = self.forward(batch.x, batch.edge_index, batch.batch).float()\n",
        "      y = batch.y.unsqueeze(-1).float()\n",
        "      loss = self.criterion(y_hat, y)\n",
        "      acc = self._compute_acc(y_hat, y)\n",
        "      self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "      y_hat = self.forward(batch.x, batch.edge_index, batch.batch).float()\n",
        "      y = batch.y.unsqueeze(-1).float()\n",
        "      loss = self.criterion(y_hat, y)\n",
        "      acc = self._compute_acc(y_hat, y)\n",
        "      self.log('test_loss', loss, logger=True)\n",
        "      self.log('test_acc', acc, logger=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(lr=self.lr, params=self.parameters())\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "vh5-JpQrQmqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Łączymy wszystko w całość używając Trainera."
      ],
      "metadata": {
        "id": "lvQArbaKUIoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "num_node_features = TUDataset(root='data/TUDataset', name='PROTEINS').num_features\n",
        "\n",
        "hidden_dim = 32\n",
        "lr = 1e-2\n",
        "\n",
        "# Initialize model and data module\n",
        "model = ProteinModel(num_node_features, hidden_dim, lr=1e-2)\n",
        "data = ProteinDataModule(batch_size=128, num_workers=2)\n",
        "\n",
        "# Define callbacks\n",
        "os.makedirs(f'data/protein/models_{hidden_dim}', exist_ok=True)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    dirpath=f'data/protein/models_{hidden_dim}',\n",
        "    filename=\"gcn-{epoch:02d}-{val_loss:.2f}\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(max_epochs=50, log_every_n_steps=7, callbacks=[checkpoint_callback, early_stopping_callback])\n",
        "trainer.fit(model, datamodule=data)\n"
      ],
      "metadata": {
        "id": "J6CA-U3RSarn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model, datamodule=data)"
      ],
      "metadata": {
        "id": "rq-QmgfMSfPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zadanie 2.3: spróbuj pozmieniać `hidden_size` i/lub `lr` (learning rate) i zobacz, jak wpływa to na jakość modelu. Możesz użyć tensorboard do porównania.**"
      ],
      "metadata": {
        "id": "jdWkdiAEUZFR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovh6euZmSKWf"
      },
      "source": [
        "## Przetwarzanie języka naturalnego\n",
        "\n",
        "Spróbujemy teraz stworzyć sieć do przewidywania tematyki tekstu. Przyjmiemy następującą strategię:\n",
        "- najpierw skorzystamy z gotowych word embeddings (tych samych o których mówiliśmy parę zajęć temu),\n",
        "- stworzymy sieć, w której word embeddings będą tworzyć periwszą warstwę,\n",
        "- nauczymy tak sklejoną sieć przewidywać jedną z 20 klas w zbiorze uczącym.\n",
        "\n",
        "To zadanie wykonamy wyjątkowo w Keras. Tak jak zwykle, parę bibliotek na początek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yx6kbsHSKWf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import Constant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeWlQfCgSKWf"
      },
      "source": [
        "### Przygotowanie danych\n",
        "\n",
        "Jako word embedding wykorzystamy model GloVe oparty o 6 miliardów tekstów. Oficjalną stroną dla tego modelu jest: https://nlp.stanford.edu/projects/glove/.\n",
        "\n",
        "Jako zbiór danych do naszych eksperymentów wykorzystamy zbiór `newsgroup`. Jest to dosyć stary zbiór danych posiadający teksty obejmujące 20 różnych tematów. Zbiór nie jest zbyt duży dzięki czemu jest szansa nauczyć model nawet lokalnie.\n",
        "\n",
        "Poniższy kod zawiera ścieżki, w których będziemy oczekiwać embeddings i danych. Ponadto ustawimy kilka parametrów, które wykorzystamy później."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPfbOAPJSKWg"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = './data/'\n",
        "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
        "TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baZyQwaASKWg"
      },
      "source": [
        "A teraz ściągnijmy potrzebne dane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcsE2T43SKWg"
      },
      "outputs": [],
      "source": [
        "!wget -O ./data/glove.6B.zip http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!wget -O ./data/news20.tar.gz http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj0wnEniSKWg"
      },
      "source": [
        "Rozkakujmy paczkę z word embeddings. Zajmie sporo miejsca, ale powinna rozpakować się dosyć szybko."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK9S59J6SKWg"
      },
      "outputs": [],
      "source": [
        "!unzip ./data/glove.6B.zip -d ./data/glove.6B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsWBT65hSKWg"
      },
      "source": [
        "Warto wspomnieć, że w Internecie można znaleźć gotowe word embeddings dla różnych języków. Poniżej pierwsze dwa trafienia dla języka niemieckiego:\n",
        "- https://devmount.github.io/GermanWordEmbeddings/\n",
        "- https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
        "\n",
        "Dobra. Teraz przeiterujemy przez cały zestaw word embeddings i stworzymy **słownik**, gdzie kluczem będzie **słowo** a wartością wektor liczb reprezentujących **embedding**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1csgxNeSKWg"
      },
      "outputs": [],
      "source": [
        "embeddings_index = {}\n",
        "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Super, mamy %s embeddingsów.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcvxeE5CSKWg"
      },
      "source": [
        "Teraz rozpakujemy zbiór danych newsgroup. To niestety potrwa dosyć długo - choć zbiór nie jest taki duży, to składa się z wielu tysięcy plików."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogXLGFhYSKWg"
      },
      "outputs": [],
      "source": [
        "!tar -xzf ./data/news20.tar.gz -C ./data # to trochę potrwa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2lsSJNcSKWg"
      },
      "source": [
        "Teraz przejedziemy przez zbiór danych i wyłuskamy listę tekstów oraz wektor etykiet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyee5a_2SKWg"
      },
      "outputs": [],
      "source": [
        "texts = []  # lista tekstów (atrybuty opisowe)\n",
        "labels_index = {}  # słownik mapujący klasę na liczbę (identyfikator klasy)\n",
        "labels = []  # lista etykiet (atrybut decyzyjny)\n",
        "\n",
        "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
        "    path = os.path.join(TEXT_DATA_DIR, name)\n",
        "    if os.path.isdir(path):\n",
        "        label_id = len(labels_index)\n",
        "        labels_index[name] = label_id\n",
        "        for fname in sorted(os.listdir(path)):\n",
        "            if fname.isdigit():\n",
        "                fpath = os.path.join(path, fname)\n",
        "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
        "                with open(fpath, **args) as f:\n",
        "                    t = f.read()\n",
        "                    i = t.find('\\n\\n')\n",
        "                    if 0 < i:\n",
        "                        t = t[i:]\n",
        "                    texts.append(t)\n",
        "                labels.append(label_id)\n",
        "\n",
        "print('Mamy %s tekstów.' % len(texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd7mKfhoSKWh"
      },
      "source": [
        "Tak się składa, że Keras oferuje własny tokenizator. Pozwoli on nam podzielić tekst na słowa i zachować tylko najpopularniejsze wyrazy (`MAX_NUM_WORDS`). Najperw odpalimy `fit`, żeby określić najpopularniejsze słowa, a następnie faktycznie stokenizujemy teksty za pomocą `texts_to_sequences`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLXTmi02SKWh"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Mamy %s unikatowych tokenów.' % len(word_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0z4LAVWSKWh"
      },
      "source": [
        "Ponieważ większość sieci lubi wejście w konkretnym rozmiarze, skorzystamy z funkcji `pad_sequences` aby ustandaryzować wejście. Za długie sekwencje słów przytniemy, a za krótkie uzupełnimy putymi znakami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR5IT1J6SKWh"
      },
      "outputs": [],
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MBjA6pRSKWh"
      },
      "source": [
        "Jako ostatni krok przygotowania, standardowe czynności:\n",
        "- kodowanie etykiet w sposób binarny,\n",
        "- podział na dane uczące i walidacyjne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHzNuWJzSKWh"
      },
      "outputs": [],
      "source": [
        "labels = to_categorical(np.asarray(labels))\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-hm5bJHSKWh"
      },
      "source": [
        "### Uczenie\n",
        "\n",
        "Teraz po tym całym przetwarzaniu danych spróbujemy stworzyć klasyfikator. Najpierw wykorzystamy nasze word embeddings z Glove żeby stworzyć pierwszą warstwę sieci. Ponieważ ograniczyliśmy słownik do `MAX_NUM_WORDS`, nasza warstwa będzie miała co najwyżej tyle wag.\n",
        "\n",
        "Pozostaje nam tylko zmapować identyfikator słowa z jego embedding, żeby zainicjalizować wagi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6j5ZWDxSKWh"
      },
      "outputs": [],
      "source": [
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfRnWUkmSKWh"
      },
      "source": [
        "Teraz stworzymy własną sieć. Zwróć uwagę, że korzystamy z 1-wymiarowych konwolucji, czyli \"filtra\" który przesuwa się po kolejnych grupach słów. Tak dla przypomnienia konwolucje 2D przesuwały kwadratowy filtr po obrazie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbw8UMZ2SKWh"
      },
      "outputs": [],
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(len(labels_index), activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ul2RS4SKWh"
      },
      "source": [
        "I uczymy sieć..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bfh0QRoSKWi"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w87iPuoJSKWi"
      },
      "source": [
        "**Zad. 3.1: Podłącz sieć do Tensorboarda i wypróbuj inne parametry lub architektury**"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}